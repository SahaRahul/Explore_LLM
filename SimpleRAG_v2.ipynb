{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.Requirement already satisfied: langchain-community in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (0.3.14)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (0.3.0)\n",
      "Requirement already satisfied: langchain-ollama in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (0.4.6)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (1.9.0.post1)\n",
      "Requirement already satisfied: unstructured in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (0.16.12)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain-community) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain-community) (3.10.10)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.14 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain-community) (0.3.14)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain-community) (0.3.29)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.125 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain-community) (0.1.135)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain-community) (2.7.1)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain-community) (8.5.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.58.1 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain-openai) (1.59.6)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain-openai) (0.8.0)\n",
      "Requirement already satisfied: ollama<1,>=0.3.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain-ollama) (0.3.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from faiss-cpu) (24.1)\n",
      "Requirement already satisfied: chardet in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from unstructured) (5.2.0)\n",
      "Requirement already satisfied: filetype in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from unstructured) (1.2.0)\n",
      "Requirement already satisfied: python-magic in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from unstructured) (0.4.27)\n",
      "Requirement already satisfied: lxml in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from unstructured) (5.3.0)\n",
      "Requirement already satisfied: nltk in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from unstructured) (3.9.1)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from unstructured) (4.12.3)\n",
      "Requirement already satisfied: emoji in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from unstructured) (2.14.0)\n",
      "Requirement already satisfied: python-iso639 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from unstructured) (2024.10.22)\n",
      "Requirement already satisfied: langdetect in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from unstructured) (1.0.9)\n",
      "Requirement already satisfied: rapidfuzz in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from unstructured) (3.11.0)\n",
      "Requirement already satisfied: backoff in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from unstructured) (2.2.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from unstructured) (4.12.2)\n",
      "Requirement already satisfied: unstructured-client in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from unstructured) (0.28.1)\n",
      "Requirement already satisfied: wrapt in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from unstructured) (1.17.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from unstructured) (4.67.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from unstructured) (6.0.0)\n",
      "Requirement already satisfied: python-oxmsg in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from unstructured) (0.0.1)\n",
      "Requirement already satisfied: html5lib in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from unstructured) (1.1)\n",
      "Requirement already satisfied: ndjson in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from unstructured) (0.3.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.15.2)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.25.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain<0.4.0,>=0.3.14->langchain-community) (0.3.5)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain<0.4.0,>=0.3.14->langchain-community) (2.9.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-community) (1.33)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-community) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-community) (3.10.7)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from beautifulsoup4->unstructured) (2.6)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from html5lib->unstructured) (1.16.0)\n",
      "Requirement already satisfied: webencodings in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from html5lib->unstructured) (0.5.1)\n",
      "Requirement already satisfied: click in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from nltk->unstructured) (8.1.8)\n",
      "Requirement already satisfied: joblib in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from nltk->unstructured) (1.4.2)\n",
      "Requirement already satisfied: olefile in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from python-oxmsg->unstructured) (0.47)\n",
      "Requirement already satisfied: aiofiles>=24.1.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from unstructured-client->unstructured) (24.1.0)\n",
      "Requirement already satisfied: cryptography>=3.1 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from unstructured-client->unstructured) (44.0.0)\n",
      "Requirement already satisfied: eval-type-backport<0.3.0,>=0.2.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from unstructured-client->unstructured) (0.2.2)\n",
      "Requirement already satisfied: jsonpath-python<2.0.0,>=1.0.6 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from unstructured-client->unstructured) (1.0.6)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from unstructured-client->unstructured) (1.6.0)\n",
      "Requirement already satisfied: pypdf>=4.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from unstructured-client->unstructured) (5.1.0)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from unstructured-client->unstructured) (2.9.0.post0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from cryptography>=3.1->unstructured-client->unstructured) (1.17.1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.14->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.14->langchain-community) (2.23.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured) (2.22)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install psycopg2 langchain-community langchain-openai langchain-ollama colorama faiss-cpu unstructured langchain huggingface_hub sentence_transformers libmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPENAI_API_KEY is set\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "if 'OPENAI_API_KEY' in os.environ:\n",
    "    print(\"OPENAI_API_KEY is set\")\n",
    "else:\n",
    "    print(\"OPENAI_API_KEY is not set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the RAG Assistant\n",
    "Step 1: Create the Index Knowledge Base (index_knowledge_base.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting index_knowledge_base_ddl_sql.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile index_knowledge_base_ddl_sql.py\n",
    "\n",
    "import os\n",
    "# import openai\n",
    "import faiss\n",
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "# from langchain.chat_models import ChatOpenAI\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from colorama import Fore, Style, init\n",
    "\n",
    "# Initialize colorama for terminal color support\n",
    "init(autoreset=True)\n",
    "\n",
    "def create_index():\n",
    "    openai_api_key = os.environ.get('OPENAI_API_KEY')  # Replace with your actual API key\n",
    "    # print(f\"testing - {openai_api_key}\")\n",
    "\n",
    "    try:\n",
    "        print(f\"{Fore.LIGHTBLUE_EX}Loading documents from the 'ddl sql' folder...{Style.RESET_ALL}\")\n",
    "        text_loader_kwargs = {\"autodetect_encoding\": True}\n",
    "        loader = DirectoryLoader(\"db_ops\", \n",
    "                                glob=\"*_ddl.sql\", \n",
    "                                loader_cls=TextLoader, \n",
    "                                loader_kwargs=text_loader_kwargs)\n",
    "        print(loader)\n",
    "        documents = loader.load()\n",
    "        print(f\"{Fore.LIGHTGREEN_EX}Documents loaded successfully!{Style.RESET_ALL}\")\n",
    "\n",
    "        print(f\"{Fore.LIGHTBLUE_EX}Indexing documents...{Style.RESET_ALL}\")\n",
    "        data_store = FAISS.from_documents(documents, \n",
    "                                          OpenAIEmbeddings())\n",
    "        data_store.save_local(\"index_ddl_sql\")\n",
    "        print(f\"{Fore.LIGHTGREEN_EX}Knowledge base indexed successfully!{Style.RESET_ALL}\")\n",
    "    except Exception as e:\n",
    "        print(f\"{Fore.RED}Error in creating index: {e}{Style.RESET_ALL}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python index_knowledge_base_ddl_sql.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing - 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\n",
      "Loading documents from the 'ddl sql' folder...\n",
      "<langchain_community.document_loaders.directory.DirectoryLoader object at 0x00000289FBBE0560>\n",
      "Documents loaded successfully!\n",
      "Indexing documents...\n",
      "Knowledge base indexed successfully!\n"
     ]
    }
   ],
   "source": [
    "from index_knowledge_base_ddl_sql import create_index\n",
    "\n",
    "create_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Create the Retrieval Pipeline (retrieval_pipeline.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting retrieval_pipeline_ddl_sql.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile retrieval_pipeline_ddl_sql.py\n",
    "\n",
    "import os\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from colorama import Fore, Style, init\n",
    "import asyncio\n",
    "\n",
    "def query_pipeline(query, data_store, llm):\n",
    "    try:\n",
    "        print(f\"{Fore.LIGHTBLUE_EX}Searching the knowledge base...{Style.RESET_ALL}\")\n",
    "        context = data_store.similarity_search(query)\n",
    "        print(f\"{Fore.LIGHTGREEN_EX}Context found:{Style.RESET_ALL} {context}\")\n",
    "\n",
    "        prompt = f\"Context: {context}\\nQuestion: {query}. Response only if context is based on knowledge base.\"\n",
    "        print(f\"{Fore.LIGHTBLUE_EX}Sending prompt to LLM...{Style.RESET_ALL}\")\n",
    "\n",
    "        response = llm.generate(prompts=[prompt])\n",
    "        print(f\"{Fore.LIGHTGREEN_EX}Received response from LLM.{Style.RESET_ALL}\")\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"{Fore.RED}Error in query pipeline: {e}{Style.RESET_ALL}\")\n",
    "        return f\"{Fore.RED}Unable to process the query. Please try again.{Style.RESET_ALL}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python retrieval_pipeline_ddl_sql.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Create the Interactive Assistant (interactive_assistant.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting interactive_assistant.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile interactive_assistant.py\n",
    "\n",
    "from retrieval_pipeline_ddl_sql import query_pipeline\n",
    "from colorama import Fore, Style, init\n",
    "\n",
    "# Initialize colorama for terminal color support\n",
    "init(autoreset=True)\n",
    "\n",
    "def interactive_mode(data_store, llm):\n",
    "    print(f\"{Fore.LIGHTBLUE_EX}Start querying your RAG assistant. Type 'exit' to quit.{Style.RESET_ALL}\")\n",
    "    while True:\n",
    "        try:\n",
    "            query = input(f\"{Fore.LIGHTGREEN_EX}Query: {Style.RESET_ALL}\")\n",
    "\n",
    "            if query.lower() == \"exit\":\n",
    "                print(f\"{Fore.LIGHTBLUE_EX}Exiting... Goodbye!{Style.RESET_ALL}\")\n",
    "                break\n",
    "\n",
    "            print(f\"{Fore.LIGHTYELLOW_EX}Processing your query...{Style.RESET_ALL}\")\n",
    "            response = query_pipeline(query, data_store, llm)\n",
    "            print(f\"{Fore.LIGHTCYAN_EX}Assistant Response: {Style.RESET_ALL}{response.generations[0][0].text}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"{Fore.RED}Error in interactive mode: {e}{Style.RESET_ALL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python interactive_assistant.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Create the Main Script (main.py)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting main_sql.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main_sql.py\n",
    "\n",
    "import os\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.embeddings import OpenAIEmbeddings\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from interactive_assistant import interactive_mode\n",
    "from index_knowledge_base_ddl_sql import create_index\n",
    "from colorama import Fore, Style, init\n",
    "\n",
    "\n",
    "global data_store \n",
    "\n",
    "# Initialize colorama for terminal color support\n",
    "init(autoreset=True)\n",
    "try:\n",
    "    print(f\"{Fore.LIGHTYELLOW_EX}Initializing the Ollama LLM...{Style.RESET_ALL}\")\n",
    "    llm = OllamaLLM(model=\"gemma2\", \n",
    "                    base_url=\"http://localhost:11434\", \n",
    "                    timeout=120, \n",
    "                    temperature=0)\n",
    "    print(f\"{Fore.LIGHTGREEN_EX}Ollama LLM initialized successfully!{Style.RESET_ALL}\")\n",
    "except Exception as e:\n",
    "    print(f\"{Fore.RED}Error initializing Ollama LLM: {e}{Style.RESET_ALL}\")\n",
    "\n",
    "print(f\"{Fore.LIGHTBLUE_EX}Initializing the RAG-powered SQL Table Column-Relationship Extractor Assistant...{Style.RESET_ALL}\")\n",
    "\n",
    "try:\n",
    "    print(f\"{Fore.LIGHTYELLOW_EX}Indexing the knowledge base...{Style.RESET_ALL}\")\n",
    "    create_index()\n",
    "    print(f\"{Fore.LIGHTGREEN_EX}Knowledge base indexed successfully!{Style.RESET_ALL}\")\n",
    "except Exception as e:\n",
    "    print(f\"{Fore.RED}Error while indexing the knowledge base: {e}{Style.RESET_ALL}\")\n",
    "\n",
    "openai_api_key = os.environ.get('OPENAI_API_KEY')  # Replace with your actual API key\n",
    "\n",
    "try:\n",
    "    print(f\"{Fore.LIGHTYELLOW_EX}Loading FAISS index...{Style.RESET_ALL}\")\n",
    "    \n",
    "    data_store = FAISS.load_local(\n",
    "        \"index_ddl_sql\",\n",
    "        OpenAIEmbeddings(),\n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "    print(f\"{Fore.LIGHTGREEN_EX}FAISS index loaded successfully!{Style.RESET_ALL}\")\n",
    "except Exception as e:\n",
    "    print(f\"{Fore.RED}Error loading FAISS index: {e}{Style.RESET_ALL}\")\n",
    "\n",
    "try:\n",
    "    print(f\"{Fore.LIGHTYELLOW_EX}Starting the interactive assistant...{Style.RESET_ALL}\")\n",
    "    interactive_mode(data_store, llm)\n",
    "except Exception as e:\n",
    "    print(f\"{Fore.RED}Error in interactive assistant: {e}{Style.RESET_ALL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# %pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
