{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ollama_client.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ollama_client.py\n",
    "\n",
    "from ollama import Client\n",
    "client = Client(\n",
    "  host='http://localhost:11434',\n",
    "  headers={'x-some-header': 'some-value'}\n",
    ")\n",
    "response = client.chat(model='llama3.2', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'Why is the sky blue?',\n",
    "  },\n",
    "])\n",
    "\n",
    "print(response['message']['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sky appears blue because of a phenomenon called Rayleigh scattering, named after the British physicist Lord Rayleigh, who first described it in the late 19th century.\n",
      "\n",
      "Here's what happens:\n",
      "\n",
      "1. When sunlight enters Earth's atmosphere, it encounters tiny molecules of gases such as nitrogen (N2) and oxygen (O2).\n",
      "2. These molecules scatter the light in all directions, but they scatter shorter (blue) wavelengths more than longer (red) wavelengths.\n",
      "3. This is because the smaller molecules are more effective at scattering the shorter wavelengths.\n",
      "4. As a result, the blue light is dispersed throughout the atmosphere, reaching our eyes from all directions.\n",
      "5. Our brains interpret this scattered blue light as the color of the sky.\n",
      "\n",
      "The reason why the sky isn't always blue is that the amount of sunlight and the angle of the sun can affect the scattering of light. For example:\n",
      "\n",
      "* During sunrise and sunset, the sun's rays have to travel through more of the atmosphere, which scatters the shorter wavelengths even more, making the sky appear redder.\n",
      "* On cloudy days, the scattered blue light is blocked by the clouds, leaving only the longer wavelengths (reds and oranges) to reach our eyes.\n",
      "* At night, there is no sunlight, so the sky appears dark.\n",
      "\n",
      "In summary, the sky appears blue because of Rayleigh scattering, which scatters shorter (blue) wavelengths of light more than longer (red) wavelengths as they pass through the atmosphere."
     ]
    }
   ],
   "source": [
    "from ollama import chat\n",
    "\n",
    "stream = chat(\n",
    "    model='llama3.2',\n",
    "    messages=[{'role': 'user', 'content': 'Why is the sky blue?'}],\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for chunk in stream:\n",
    "  print(chunk['message']['content'], end='', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AsyncClient without stream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ollama_client_asyncio.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ollama_client_asyncio.py\n",
    "\n",
    "import asyncio\n",
    "from ollama import AsyncClient\n",
    "\n",
    "async def chat():\n",
    "  message = {'role': 'user', 'content': 'Why is the sky blue?'}\n",
    "  response = await AsyncClient().chat(model='llama3.2', messages=[message])\n",
    "  print(response['message']['content'])\n",
    "\n",
    "asyncio.run(chat())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AsyncClient with stream=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing ollama_client_stream.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ollama_client_stream.py\n",
    "\n",
    "import asyncio\n",
    "from ollama import AsyncClient\n",
    "\n",
    "async def chat():\n",
    "  message = {'role': 'user', 'content': 'Why is the sky blue?'}\n",
    "  async for part in await AsyncClient().chat(model='llama3.2', messages=[message], stream=True):\n",
    "    print(part['message']['content'], end='', flush=True)\n",
    "\n",
    "asyncio.run(chat())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rahul\\Documents\\Personal_Learning\\GenAI LLM\\rag_code_assistant\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rahul\\Documents\\Personal_Learning\\GenAI LLM\\.venv\\Lib\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%mkdir rag_code_assistant\n",
    "%cd rag_code_assistant\n",
    "%mkdir code_snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-community in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (0.3.14)Note: you may need to restart the kernel to use updated packages."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[notice] A new release of pip is available: 24.2 -> 24.3.1"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (0.3.0)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-ollama in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (0.4.6)\n",
      "Requirement already satisfied: faiss-cpu in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (1.9.0.post1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unstructured\n",
      "  Downloading unstructured-0.16.12-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain-community) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain-community) (3.10.10)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: httpx-sse<0.5.0,>=0.4.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.14 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain-community) (0.3.14)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain-community) (0.3.29)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.125 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain-community) (0.1.135)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain-community) (2.7.1)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain-community) (8.5.0)\n",
      "Requirement already satisfied: openai<2.0.0,>=1.58.1 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain-openai) (1.59.6)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain-openai) (0.8.0)\n",
      "Requirement already satisfied: ollama<1,>=0.3.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain-ollama) (0.3.3)\n",
      "Requirement already satisfied: packaging in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from faiss-cpu) (24.1)\n",
      "Collecting chardet (from unstructured)\n",
      "  Downloading chardet-5.2.0-py3-none-any.whl.metadata (3.4 kB)\n",
      "Collecting filetype (from unstructured)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting python-magic (from unstructured)\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: lxml in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from unstructured) (5.3.0)\n",
      "Collecting nltk (from unstructured)\n",
      "  Downloading nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting beautifulsoup4 (from unstructured)\n",
      "  Downloading beautifulsoup4-4.12.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting emoji (from unstructured)\n",
      "  Downloading emoji-2.14.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting python-iso639 (from unstructured)\n",
      "  Downloading python_iso639-2024.10.22-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting langdetect (from unstructured)\n",
      "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
      "     ---------------------------------------- 0.0/981.5 kB ? eta -:--:--\n",
      "     ---------- ----------------------------- 262.1/981.5 kB ? eta -:--:--\n",
      "     -------------------- ----------------- 524.3/981.5 kB 2.4 MB/s eta 0:00:01\n",
      "     -------------------------------------- 981.5/981.5 kB 2.3 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting rapidfuzz (from unstructured)\n",
      "  Downloading rapidfuzz-3.11.0-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting backoff (from unstructured)\n",
      "  Using cached backoff-2.2.1-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from unstructured) (4.12.2)\n",
      "Collecting unstructured-client (from unstructured)\n",
      "  Downloading unstructured_client-0.28.1-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: wrapt in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from unstructured) (1.17.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from unstructured) (4.67.1)\n",
      "Requirement already satisfied: psutil in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from unstructured) (6.0.0)\n",
      "Collecting python-oxmsg (from unstructured)\n",
      "  Downloading python_oxmsg-0.0.1-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting html5lib (from unstructured)\n",
      "  Downloading html5lib-1.1-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Collecting ndjson (from unstructured)\n",
      "  Downloading ndjson-0.3.1-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.15.2)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.25.0)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain<0.4.0,>=0.3.14->langchain-community) (0.3.5)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain<0.4.0,>=0.3.14->langchain-community) (2.9.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain-community) (1.33)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-community) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-community) (3.10.7)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langsmith<0.3,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (4.6.2.post1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (0.8.2)\n",
      "Requirement already satisfied: sniffio in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from openai<2.0.0,>=1.58.1->langchain-openai) (1.3.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4->unstructured)\n",
      "  Downloading soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: six>=1.9 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from html5lib->unstructured) (1.16.0)\n",
      "Collecting webencodings (from html5lib->unstructured)\n",
      "  Downloading webencodings-0.5.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting click (from nltk->unstructured)\n",
      "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: joblib in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from nltk->unstructured) (1.4.2)\n",
      "Collecting olefile (from python-oxmsg->unstructured)\n",
      "  Downloading olefile-0.47-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting aiofiles>=24.1.0 (from unstructured-client->unstructured)\n",
      "  Downloading aiofiles-24.1.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting cryptography>=3.1 (from unstructured-client->unstructured)\n",
      "  Downloading cryptography-44.0.0-cp39-abi3-win_amd64.whl.metadata (5.7 kB)\n",
      "Collecting eval-type-backport<0.3.0,>=0.2.0 (from unstructured-client->unstructured)\n",
      "  Downloading eval_type_backport-0.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting jsonpath-python<2.0.0,>=1.0.6 (from unstructured-client->unstructured)\n",
      "  Downloading jsonpath_python-1.0.6-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: nest-asyncio>=1.6.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from unstructured-client->unstructured) (1.6.0)\n",
      "Collecting pypdf>=4.0 (from unstructured-client->unstructured)\n",
      "  Downloading pypdf-5.1.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from unstructured-client->unstructured) (2.9.0.post0)\n",
      "Collecting cffi>=1.12 (from cryptography>=3.1->unstructured-client->unstructured)\n",
      "  Downloading cffi-1.17.1-cp312-cp312-win_amd64.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.14->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.14->langchain-community) (2.23.4)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.0)\n",
      "Collecting pycparser (from cffi>=1.12->cryptography>=3.1->unstructured-client->unstructured)\n",
      "  Downloading pycparser-2.22-py3-none-any.whl.metadata (943 bytes)\n",
      "Downloading unstructured-0.16.12-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ----------- ---------------------------- 0.5/1.7 MB 3.4 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 1.0/1.7 MB 3.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 3.3 MB/s eta 0:00:00\n",
      "Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading beautifulsoup4-4.12.3-py3-none-any.whl (147 kB)\n",
      "Downloading chardet-5.2.0-py3-none-any.whl (199 kB)\n",
      "Downloading emoji-2.14.0-py3-none-any.whl (586 kB)\n",
      "   ---------------------------------------- 0.0/586.9 kB ? eta -:--:--\n",
      "   ---------------------------------------- 586.9/586.9 kB 2.3 MB/s eta 0:00:00\n",
      "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading html5lib-1.1-py2.py3-none-any.whl (112 kB)\n",
      "Downloading ndjson-0.3.1-py2.py3-none-any.whl (5.3 kB)\n",
      "Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "   ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 0.8/1.5 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.5/1.5 MB 4.2 MB/s eta 0:00:00\n",
      "Downloading python_iso639-2024.10.22-py3-none-any.whl (274 kB)\n",
      "Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Downloading python_oxmsg-0.0.1-py3-none-any.whl (31 kB)\n",
      "Downloading rapidfuzz-3.11.0-cp312-cp312-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 0.8/1.6 MB 4.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 3.9 MB/s eta 0:00:00\n",
      "Downloading unstructured_client-0.28.1-py3-none-any.whl (62 kB)\n",
      "Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
      "Downloading cryptography-44.0.0-cp39-abi3-win_amd64.whl (3.2 MB)\n",
      "   ---------------------------------------- 0.0/3.2 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 0.8/3.2 MB 4.2 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 2.1/3.2 MB 5.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 3.2/3.2 MB 5.9 MB/s eta 0:00:00\n",
      "Downloading eval_type_backport-0.2.2-py3-none-any.whl (5.8 kB)\n",
      "Downloading jsonpath_python-1.0.6-py3-none-any.whl (7.6 kB)\n",
      "Downloading pypdf-5.1.0-py3-none-any.whl (297 kB)\n",
      "Downloading soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Downloading click-8.1.8-py3-none-any.whl (98 kB)\n",
      "Downloading olefile-0.47-py2.py3-none-any.whl (114 kB)\n",
      "Downloading webencodings-0.5.1-py2.py3-none-any.whl (11 kB)\n",
      "Downloading cffi-1.17.1-cp312-cp312-win_amd64.whl (181 kB)\n",
      "Downloading pycparser-2.22-py3-none-any.whl (117 kB)\n",
      "Building wheels for collected packages: langdetect\n",
      "  Building wheel for langdetect (setup.py): started\n",
      "  Building wheel for langdetect (setup.py): finished with status 'done'\n",
      "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993313 sha256=8ff672ff54f45d8ebaa30127ca942b5ffb1bd7a01372c816029d9965671e0975\n",
      "  Stored in directory: c:\\users\\rahul\\appdata\\local\\pip\\cache\\wheels\\c1\\67\\88\\e844b5b022812e15a52e4eaa38a1e709e99f06f6639d7e3ba7\n",
      "Successfully built langdetect\n",
      "Installing collected packages: webencodings, ndjson, filetype, soupsieve, rapidfuzz, python-magic, python-iso639, pypdf, pycparser, olefile, langdetect, jsonpath-python, html5lib, eval-type-backport, emoji, click, chardet, backoff, aiofiles, python-oxmsg, nltk, cffi, beautifulsoup4, cryptography, unstructured-client, unstructured\n",
      "Successfully installed aiofiles-24.1.0 backoff-2.2.1 beautifulsoup4-4.12.3 cffi-1.17.1 chardet-5.2.0 click-8.1.8 cryptography-44.0.0 emoji-2.14.0 eval-type-backport-0.2.2 filetype-1.2.0 html5lib-1.1 jsonpath-python-1.0.6 langdetect-1.0.9 ndjson-0.3.1 nltk-3.9.1 olefile-0.47 pycparser-2.22 pypdf-5.1.0 python-iso639-2024.10.22 python-magic-0.4.27 python-oxmsg-0.0.1 rapidfuzz-3.11.0 soupsieve-2.6 unstructured-0.16.12 unstructured-client-0.28.1 webencodings-0.5.1\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain-community langchain-openai langchain-ollama colorama faiss-cpu unstructured"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (4.48.0)\n",
      "Requirement already satisfied: torch in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from transformers) (3.16.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from transformers) (0.27.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from torch) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from requests->transformers) (2024.8.30)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://dzone.com/articles/enhance-your-workflow-with-ollama-langchain-and-rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (0.3.14)\n",
      "Requirement already satisfied: huggingface_hub in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (0.27.1)\n",
      "Collecting sentence_transformers\n",
      "  Downloading sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain) (2.0.35)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain) (3.10.10)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.29 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain) (0.3.29)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.3 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain) (0.3.5)\n",
      "Requirement already satisfied: langsmith<0.3,>=0.1.17 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain) (0.1.135)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain) (1.26.4)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain) (2.9.2)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from huggingface_hub) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from huggingface_hub) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from huggingface_hub) (24.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from sentence_transformers) (4.48.0)\n",
      "Requirement already satisfied: torch>=1.11.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from sentence_transformers) (2.5.1)\n",
      "Collecting scikit-learn (from sentence_transformers)\n",
      "  Downloading scikit_learn-1.6.1-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
      "Collecting scipy (from sentence_transformers)\n",
      "  Downloading scipy-1.15.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting Pillow (from sentence_transformers)\n",
      "  Downloading pillow-11.1.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.15.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.29->langchain) (1.33)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain) (3.10.7)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from langsmith<0.3,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (3.1.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (75.8.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from torch>=1.11.0->sentence_transformers) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from sympy==1.13.1->torch>=1.11.0->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from transformers<5.0.0,>=4.41.0->sentence_transformers) (0.5.2)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence_transformers)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence_transformers)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: anyio in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.0.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.3,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.29->langchain) (3.0.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain) (0.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\rahul\\documents\\personal_learning\\genai llm\\.venv\\lib\\site-packages (from jinja2->torch>=1.11.0->sentence_transformers) (3.0.2)\n",
      "Downloading sentence_transformers-3.3.1-py3-none-any.whl (268 kB)\n",
      "Downloading pillow-11.1.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ------------------- -------------------- 1.3/2.6 MB 6.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.6/2.6 MB 6.9 MB/s eta 0:00:00\n",
      "Downloading scikit_learn-1.6.1-cp312-cp312-win_amd64.whl (11.1 MB)\n",
      "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
      "   ---- ----------------------------------- 1.3/11.1 MB 8.4 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 2.9/11.1 MB 7.6 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 4.7/11.1 MB 8.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 7.1/11.1 MB 8.9 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 9.2/11.1 MB 9.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.1/11.1 MB 9.4 MB/s eta 0:00:00\n",
      "Downloading scipy-1.15.1-cp312-cp312-win_amd64.whl (43.6 MB)\n",
      "   ---------------------------------------- 0.0/43.6 MB ? eta -:--:--\n",
      "   - -------------------------------------- 1.3/43.6 MB 6.7 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 3.7/43.6 MB 9.9 MB/s eta 0:00:05\n",
      "   ----- ---------------------------------- 6.0/43.6 MB 10.3 MB/s eta 0:00:04\n",
      "   ------- -------------------------------- 8.4/43.6 MB 10.6 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 10.7/43.6 MB 10.8 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 12.6/43.6 MB 10.4 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 14.4/43.6 MB 10.3 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 16.3/43.6 MB 10.0 MB/s eta 0:00:03\n",
      "   ---------------- ----------------------- 17.8/43.6 MB 9.9 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 19.9/43.6 MB 9.8 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 21.8/43.6 MB 9.8 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 23.9/43.6 MB 9.7 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 25.4/43.6 MB 9.6 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 27.8/43.6 MB 9.7 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 29.1/43.6 MB 9.6 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 31.5/43.6 MB 9.6 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 33.6/43.6 MB 9.6 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 34.9/43.6 MB 9.5 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 36.7/43.6 MB 9.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 37.7/43.6 MB 9.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 39.3/43.6 MB 9.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 40.4/43.6 MB 9.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  42.7/43.6 MB 9.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 43.6/43.6 MB 9.0 MB/s eta 0:00:00\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, Pillow, joblib, scikit-learn, sentence_transformers\n",
      "Successfully installed Pillow-11.1.0 joblib-1.4.2 scikit-learn-1.6.1 scipy-1.15.1 sentence_transformers-3.3.1 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain huggingface_hub sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the RAG Assistant\n",
    "Step 1: Create the Index Knowledge Base (index_knowledge_base.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting index_knowledge_base.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile index_knowledge_base.py\n",
    "\n",
    "import os\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from colorama import Fore, Style, init\n",
    "\n",
    "# Initialize colorama for terminal color support\n",
    "init(autoreset=True)\n",
    "\n",
    "def create_index():\n",
    "    openai_api_key = os.environ.get('OPENAI_API_KEY')  # Replace with your actual API key\n",
    "    try:\n",
    "        print(f\"{Fore.LIGHTBLUE_EX}Loading documents from the 'code_snippets' folder...{Style.RESET_ALL}\")\n",
    "        loader = DirectoryLoader(\"rag_code_assistant/code_snippets\", glob=\"*.py\")\n",
    "        documents = loader.load()\n",
    "        print(f\"{Fore.LIGHTGREEN_EX}Documents loaded successfully!{Style.RESET_ALL}\")\n",
    "\n",
    "        print(f\"{Fore.LIGHTBLUE_EX}Indexing documents...{Style.RESET_ALL}\")\n",
    "        data_store = FAISS.from_documents(documents, OpenAIEmbeddings(openai_api_key=openai_api_key))\n",
    "        data_store.save_local(\"index\")\n",
    "        print(f\"{Fore.LIGHTGREEN_EX}Knowledge base indexed successfully!{Style.RESET_ALL}\")\n",
    "    except Exception as e:\n",
    "        print(f\"{Fore.RED}Error in creating index: {e}{Style.RESET_ALL}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python index_knowledge_base.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2: Create the Retrieval Pipeline (retrieval_pipeline.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting retrieval_pipeline.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile retrieval_pipeline.py\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from colorama import Fore, Style, init\n",
    "import asyncio\n",
    "\n",
    "# Initialize colorama for terminal color support\n",
    "init(autoreset=True)\n",
    "\n",
    "openai_api_key = os.environ.get('OPENAI_API_KEY')  # Replace with your actual API key\n",
    "\n",
    "try:\n",
    "    print(f\"{Fore.LIGHTYELLOW_EX}Loading FAISS index...{Style.RESET_ALL}\")\n",
    "    data_store = FAISS.load_local(\n",
    "        \"index\",\n",
    "        OpenAIEmbeddings(openai_api_key=openai_api_key),\n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "    print(f\"{Fore.LIGHTGREEN_EX}FAISS index loaded successfully!{Style.RESET_ALL}\")\n",
    "except Exception as e:\n",
    "    print(f\"{Fore.RED}Error loading FAISS index: {e}{Style.RESET_ALL}\")\n",
    "\n",
    "try:\n",
    "    print(f\"{Fore.LIGHTYELLOW_EX}Initializing the Ollama LLM...{Style.RESET_ALL}\")\n",
    "    llm = OllamaLLM(model=\"llama3.2\", base_url=\"http://localhost:11434\", timeout=120)\n",
    "    print(f\"{Fore.LIGHTGREEN_EX}Ollama LLM initialized successfully!{Style.RESET_ALL}\")\n",
    "except Exception as e:\n",
    "    print(f\"{Fore.RED}Error initializing Ollama LLM: {e}{Style.RESET_ALL}\")\n",
    "\n",
    "def query_pipeline(query):\n",
    "    try:\n",
    "        print(f\"{Fore.LIGHTBLUE_EX}Searching the knowledge base...{Style.RESET_ALL}\")\n",
    "        context = data_store.similarity_search(query)\n",
    "        print(f\"{Fore.LIGHTGREEN_EX}Context found:{Style.RESET_ALL} {context}\")\n",
    "\n",
    "        prompt = f\"Context: {context}\\nQuestion: {query}. Response only if context is relevant to calculator code, else response sorry cannot help you in this context.\"\n",
    "        print(f\"{Fore.LIGHTBLUE_EX}Sending prompt to LLM...{Style.RESET_ALL}\")\n",
    "        response = llm.generate(prompts=[prompt])\n",
    "        print(f\"{Fore.LIGHTGREEN_EX}Received response from LLM.{Style.RESET_ALL}\")\n",
    "        return response\n",
    "    except Exception as e:\n",
    "        print(f\"{Fore.RED}Error in query pipeline: {e}{Style.RESET_ALL}\")\n",
    "        return f\"{Fore.RED}Unable to process the query. Please try again.{Style.RESET_ALL}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 3: Create the Interactive Assistant (interactive_assistant.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting interactive_assistant.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile interactive_assistant.py\n",
    "\n",
    "from retrieval_pipeline import query_pipeline\n",
    "from colorama import Fore, Style, init\n",
    "\n",
    "# Initialize colorama for terminal color support\n",
    "init(autoreset=True)\n",
    "\n",
    "def interactive_mode():\n",
    "    print(f\"{Fore.LIGHTBLUE_EX}Start querying your RAG assistant. Type 'exit' to quit.{Style.RESET_ALL}\")\n",
    "    while True:\n",
    "        try:\n",
    "            query = input(f\"{Fore.LIGHTGREEN_EX}Query: {Style.RESET_ALL}\")\n",
    "\n",
    "            if query.lower() == \"exit\":\n",
    "                print(f\"{Fore.LIGHTBLUE_EX}Exiting... Goodbye!{Style.RESET_ALL}\")\n",
    "                break\n",
    "\n",
    "            print(f\"{Fore.LIGHTYELLOW_EX}Processing your query...{Style.RESET_ALL}\")\n",
    "            response = query_pipeline(query)\n",
    "            print(f\"{Fore.LIGHTCYAN_EX}Assistant Response: {Style.RESET_ALL}{response.generations[0][0].text}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"{Fore.RED}Error in interactive mode: {e}{Style.RESET_ALL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 4: Create the Main Script (main.py)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting main.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile main.py \n",
    "\n",
    "from interactive_assistant import interactive_mode\n",
    "from index_knowledge_base import create_index\n",
    "from colorama import Fore, Style, init\n",
    "\n",
    "# Initialize colorama for terminal color support\n",
    "init(autoreset=True)\n",
    "\n",
    "print(f\"{Fore.LIGHTBLUE_EX}Initializing the RAG-powered Code Assistant...{Style.RESET_ALL}\")\n",
    "\n",
    "try:\n",
    "    print(f\"{Fore.LIGHTYELLOW_EX}Indexing the knowledge base...{Style.RESET_ALL}\")\n",
    "    create_index()\n",
    "    print(f\"{Fore.LIGHTGREEN_EX}Knowledge base indexed successfully!{Style.RESET_ALL}\")\n",
    "except Exception as e:\n",
    "    print(f\"{Fore.RED}Error while indexing the knowledge base: {e}{Style.RESET_ALL}\")\n",
    "\n",
    "try:\n",
    "    print(f\"{Fore.LIGHTYELLOW_EX}Starting the interactive assistant...{Style.RESET_ALL}\")\n",
    "    interactive_mode()\n",
    "except Exception as e:\n",
    "    print(f\"{Fore.RED}Error in interactive assistant: {e}{Style.RESET_ALL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
